{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@arthur_juan***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    API KEY: ZpsQt4djTkQaRfHdIvwM4OVEQ\n",
    "#    API Scret: qnAxY4HpajivQq76Gmz5uzks4Dp5AwMgZh5wopLI0vOYzEZs83\n",
    "#\n",
    "#    Access Token: 904543009957715968-zw2LsSLpUxRXol9z6FxatNjUAT01Wbh\n",
    "#    Access Token Secret: dPULw1D3Q0fvF6CntlbTFvDdn3jO7MSK8e3ZiLfbNKdEJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @arthur_juan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Teste'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Teste'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8e912bc81725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#dados[\"Treinamento\"]=\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdados\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Teste'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Teste'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dados = pd.read_excel('VIVE-EN.xlsx')\n",
    "\n",
    "#dados[\"Treinamento\"]=\n",
    "\n",
    "dados['Teste']\n",
    "\n",
    "\n",
    "\n",
    "#dados['Treinamento'].str.replace('[\":\",\";\",\"[\",\"]\"]', '')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Treinamento\":[]})\n",
    "formatado=[]\n",
    "formatado2=[]\n",
    "\n",
    "for i in range(len(dados)):\n",
    "    formatado.append(dados['Treinamento'][i].translate({ord(c): None for c in \"@:;,[]“/{}()+=-_*\"}))\n",
    "    formatado2.append(dados['Relevância'][i])\n",
    "df[\"Treinamento\"]=formatado\n",
    "df[\"Relevância\"]=formatado2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df['range'] = df['range'].str.replace(',','-')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'htc': 13, 'vive': 11, 'a': 7, 'i': 7, 'and': 6, 'the': 5, 'oculus': 4, 'vr': 4, 'has': 3, 'in': 3, 'amazing': 3, 'it': 3, 'on': 3, 'now': 3, '\"as': 2, 'someone': 2, 'who': 2, 'been': 2, 'software': 2, 'industry': 2, 'for': 2, 'almost': 2, 'decade': 2, 'think': 2, 'it’s': 2, 'how': 2, 'good': 2, 'rift': 2, \"it's\": 2, 'to': 2, 'me': 2, 'that': 2, 'will': 2, 'passive': 2, '#vr': 2, '#virtualreality': 2, 'price': 2, 'htcvive': 2, 'are': 2, 'vive.': 2, 'crapping': 2, 'vive!': 2, 'my': 2, 'works\"…': 1, 'https//t.co/t3om5itbmg': 1, 'bandainamcous': 1, 'playstationuk': 1, 'this': 1, 'shld': 1, 'be': 1, 'too': 1, 'clear': 1, 'shape': 1, 'shift': 1, 'experiences.': 1, 'remarkable': 1, 'imagination.': 1, 'he': 1, 'leaders': 1, 'headsets': 1, 'reduced': 1, 'by': 1, '$200': 1, 'award': 1, 'winning': 1, 'headset': 1, 'its': 1, '$754.56…': 1, 'https//t.co/k2ac75aog8': 1, \"don't\": 1, 'miss': 1, 'gets': 1, 'major': 1, 'cut': 1, '$600': 1, 'https//t.co/u7vrrciekz': 1, 'agraylin': 1, 'obriend17': 1, 'https//t.co/mb1hanel3b': 1, 'jidespark': 1, '26': 1, 'startups': 1, 'debut': 1, 'at': 1, 'htc’s': 1, 'demo': 1, 'day': 1, 'https//t.co/neidd3bhiz': 1, 'https//t.co/rlij6wx5zs': 1, 'vs.': 1, 'prices': 1, 'lower': 1, 'but': 1, 'our': 1, 'favorite': 1, 'remains': 1, 'same': 1, '#graphics': 1, 'https//t.co/5vt6ozuedi': 1, 'muhammedallia': 1, 'okie': 1, 'dokie.': 1, 'personally': 1, 'i’d': 1, 'go': 1, 'i’m': 1, 'debating': 1, 'gaming': 1, 'pc': 1, 'myself': 1, 'or': 1, 'new': 1, 'imac.': 1, 'shares': 1, 'rebounds': 1, 'back': 1, 'of': 1, 'enthusiasm': 1, 'https//t.co/gdwuxwagac': 1, 'lilyotron': 1, 'works\"': 1, 'https//t.co/…': 1, 'ahhhhhh': 1, 'fuuuuuuu!': 1, 'love': 1, '-or-': 1, 'rift?': 1, 'let': 1, 'show': 1, 'you.': 1, 'https//t.co/owfl2viwrw': 1, 'predict': 1, 're-imagine': 1, 'connections.': 1, 'unreal': 1, 'experience.': 1, 'omarsebali': 1, 'oh': 1, 'have': 1, 'an': 1, 'less': 1, 'limiting': 1, 'ahhh': 1, \"i'm\": 1, 'falling!': 1, 'hate': 1, 'came': 1, 'with': 1, 'malfunction': 1, 'father': 1, 'trying': 1, 'fix': 1, \"didn't\": 1, 'know': 1, 'we': 1, 'bought': 1, 'build': 1, 'your': 1, 'own': 1, 'kit': 1})\n"
     ]
    }
   ],
   "source": [
    "pR = []\n",
    "pIR = []\n",
    "\n",
    "\n",
    "for i in range(len(dados)):\n",
    "    if df[\"Relevância\"][i] == 0:\n",
    "        pIR.append(df['Treinamento'][i])\n",
    "    else:\n",
    "        pR.append(df['Treinamento'][i])\n",
    "\n",
    "\n",
    "lpr = []\n",
    "lpir = []\n",
    "\n",
    "\n",
    "PR = (16/300)\n",
    "PIR = (300 - 16)/300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(pR)):\n",
    "    lpr += pR[i].split()\n",
    "\n",
    "for i in range(len(pIR)):\n",
    "    lpir += pIR[i].split()\n",
    "    \n",
    "#palaras_delete = [\"a\",\"i\",\"o\",\"on\",\"who\",\"has\",\"in\",\"it\",\"now\",\"as\",\"me\",\"same\",\"day\",\"too\"]\n",
    "#stopwords = [\"htc\",'vive','']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#print(lpr)\n",
    "from collections import Counter\n",
    "\n",
    "fr  = Counter(lpr)\n",
    "fir = Counter(lpir)\n",
    "print(fr)\n",
    "#print(fir)\n",
    "\n",
    "dicta = {}\n",
    "\n",
    "dfqr = {}\n",
    "\n",
    "for k,v in fr.items():\n",
    "    dfqr[k] = v\n",
    "\n",
    "    \n",
    "\n",
    "dfqir = {}\n",
    "\n",
    "for k,v in fir.items():\n",
    "    dfqir[k] = v\n",
    "\n",
    "    \n",
    "#x = len(lpr)\n",
    "#print(x)\n",
    "\n",
    "#dfpr = pd.DataFrame()\n",
    "#dfpi = pd.DataFrame()\n",
    "#dfpr[\"R\"]=lpr\n",
    "#dfpi[\"IR\"]=lpir\n",
    "\n",
    "#dfpr.describe()\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(3):\n",
    "#    print(fr[i]/250)\n",
    "#print(len(lpir))\n",
    "#print(fir) \n",
    "#print(dfqir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'htc': 13, 'vive': 11, 'a': 7, 'i': 7, 'and': 6, 'the': 5, 'oculus': 4, 'vr': 4, 'has': 3, 'in': 3, 'amazing': 3, 'it': 3, 'on': 3, 'now': 3, '\"as': 2, 'someone': 2, 'who': 2, 'been': 2, 'software': 2, 'industry': 2, 'for': 2, 'almost': 2, 'decade': 2, 'think': 2, 'it’s': 2, 'how': 2, 'good': 2, 'rift': 2, \"it's\": 2, 'to': 2, 'me': 2, 'that': 2, 'will': 2, 'passive': 2, '#vr': 2, '#virtualreality': 2, 'price': 2, 'htcvive': 2, 'are': 2, 'vive.': 2, 'crapping': 2, 'vive!': 2, 'my': 2, 'works\"…': 1, 'https//t.co/t3om5itbmg': 1, 'bandainamcous': 1, 'playstationuk': 1, 'this': 1, 'shld': 1, 'be': 1, 'too': 1, 'clear': 1, 'shape': 1, 'shift': 1, 'experiences.': 1, 'remarkable': 1, 'imagination.': 1, 'he': 1, 'leaders': 1, 'headsets': 1, 'reduced': 1, 'by': 1, '$200': 1, 'award': 1, 'winning': 1, 'headset': 1, 'its': 1, '$754.56…': 1, 'https//t.co/k2ac75aog8': 1, \"don't\": 1, 'miss': 1, 'gets': 1, 'major': 1, 'cut': 1, '$600': 1, 'https//t.co/u7vrrciekz': 1, 'agraylin': 1, 'obriend17': 1, 'https//t.co/mb1hanel3b': 1, 'jidespark': 1, '26': 1, 'startups': 1, 'debut': 1, 'at': 1, 'htc’s': 1, 'demo': 1, 'day': 1, 'https//t.co/neidd3bhiz': 1, 'https//t.co/rlij6wx5zs': 1, 'vs.': 1, 'prices': 1, 'lower': 1, 'but': 1, 'our': 1, 'favorite': 1, 'remains': 1, 'same': 1, '#graphics': 1, 'https//t.co/5vt6ozuedi': 1, 'muhammedallia': 1, 'okie': 1, 'dokie.': 1, 'personally': 1, 'i’d': 1, 'go': 1, 'i’m': 1, 'debating': 1, 'gaming': 1, 'pc': 1, 'myself': 1, 'or': 1, 'new': 1, 'imac.': 1, 'shares': 1, 'rebounds': 1, 'back': 1, 'of': 1, 'enthusiasm': 1, 'https//t.co/gdwuxwagac': 1, 'lilyotron': 1, 'works\"': 1, 'https//t.co/…': 1, 'ahhhhhh': 1, 'fuuuuuuu!': 1, 'love': 1, '-or-': 1, 'rift?': 1, 'let': 1, 'show': 1, 'you.': 1, 'https//t.co/owfl2viwrw': 1, 'predict': 1, 're-imagine': 1, 'connections.': 1, 'unreal': 1, 'experience.': 1, 'omarsebali': 1, 'oh': 1, 'have': 1, 'an': 1, 'less': 1, 'limiting': 1, 'ahhh': 1, \"i'm\": 1, 'falling!': 1, 'hate': 1, 'came': 1, 'with': 1, 'malfunction': 1, 'father': 1, 'trying': 1, 'fix': 1, \"didn't\": 1, 'know': 1, 'we': 1, 'bought': 1, 'build': 1, 'your': 1, 'own': 1, 'kit': 1})\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#dfqr = {}\n",
    "\n",
    "#for k,v in fr.items():\n",
    "#    dfqr[k] = v\n",
    "\n",
    "    \n",
    "\n",
    "#dfqir = {}\n",
    "#\n",
    "#for k,v in fir.items():\n",
    "#    dfqir[k] = v\n",
    "\n",
    "\n",
    "\n",
    "print(fr)\n",
    "print(fr[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "0.000168321831341525\n"
     ]
    }
   ],
   "source": [
    "palavrasR = len(lpr)\n",
    "palavrasIR = len(lpir)\n",
    "listu = Counter(lpr + lpir)\n",
    "\n",
    "print(palavrasR)\n",
    "print(1/(len(listu)+palavrasIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05333333333333334, 0.009582477754962354, 0.008213552361396304, 0.002053388090349076]\n",
      "[0.9466666666666667, 0.0390506648712338, 0.0370308028951355, 0.000168321831341525]\n",
      "Irrelevante\n",
      "4.5970300695479e-10 2.1813541439796068e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "listu = Counter(lpr + lpir)\n",
    "total = len(listu)\n",
    "palavrasR = len(lpr)\n",
    "palavrasIR = len(lpir)\n",
    "\n",
    "stringy = \"htc vive good\"\n",
    "\n",
    "\n",
    "listp = stringy.split()\n",
    "\n",
    "x = PR\n",
    "y = PIR\n",
    "\n",
    "\n",
    "listR = [x]\n",
    "listIR = [y]\n",
    "\n",
    "\n",
    "for i in range(len(listp)):\n",
    "    if listp[i] in lpr:\n",
    "        listR.append((fr[listp[i]]+1)/(total+palavrasR))\n",
    "        #print(listp[i] )\n",
    "        #print(\" RELEVANTE\")\n",
    "        #print(listR[i])\n",
    "    else:\n",
    "        listR.append(1/(total+palavrasR))\n",
    "        #print(\"N TEM\")\n",
    "        #print(listR[i])\n",
    "        \n",
    "for i in range(len(listp)):\n",
    "    if listp[i] in lpir:\n",
    "        #print(dfqir[listp[i]]) \n",
    "        \n",
    "        listIR.append((fir[listp[i]]+1)/(total+palavrasIR))\n",
    "        #print(listp[i])\n",
    "        #print(\" IRRELEVANTE\")\n",
    "        #print(listIR[i])\n",
    "    else:\n",
    "        listIR.append(1/(total+palavrasIR))\n",
    "        #print(\"N TEM\")\n",
    "        #print(listIR[i])\n",
    "        \n",
    "x = PR\n",
    "y = PIR\n",
    "\n",
    "print(listR)\n",
    "print(listIR)        \n",
    "for i in range(len(listR)):\n",
    "    x*=listR[i]\n",
    "    y*=listIR[i]\n",
    "    #print(x,\"{}\".format(i))\n",
    "    #print(y)\n",
    "\n",
    "    \n",
    "#print(PRP)\n",
    "#print(PIRP)\n",
    "\n",
    "if x > y:\n",
    "    print(\"Relevante\")\n",
    "else:\n",
    "    print(\"Irrelevante\")\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
